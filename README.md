# Network Security ML Pipeline

A production-ready Machine Learning pipeline for Network Security analysis with MongoDB Atlas integration, implementing modular architecture and ML engineering best practices.

## âœ¨ Features

- ğŸ”„ **MongoDB Atlas Integration** - Cloud-based data ingestion
- ğŸ“Š **Data Validation** - Schema validation & statistical drift detection
- ğŸ”§ **Data Transformation** - Automated preprocessing with KNN Imputer
- ğŸ“ **Artifact Management** - Timestamped experiment tracking
- ğŸ—ï¸ **Modular Architecture** - Scalable, maintainable codebase
- ğŸ“ **Production-Grade** - Comprehensive logging & error handling

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- MongoDB Atlas account

### Installation

```bash
# Clone repository
git clone <your-repo-url>
cd NetworkSecurity

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
pip install -e .
```

### Configuration

1. Create `.env` file:
```env
MONGO_DB_URL=your_mongodb_atlas_connection_string
```

2. Update constants in `networksecurity/constant/training_pipeline/__init__.py`:
```python
DATA_INGESTION_DATABASE_NAME: str = "YourDatabaseName"
DATA_INGESTION_COLLECTION_NAME: str = "YourCollectionName"
```

3. Upload data to MongoDB:
```bash
python push_data.py
```

### Run Pipeline

```bash
python main.py
```

## ğŸ“‹ Pipeline Components

### 1. Data Ingestion
- Reads from MongoDB Atlas
- Exports to feature store
- Splits train/test (80/20)

### 2. Data Validation
- Schema validation (column count)
- Drift detection (Kolmogorov-Smirnov test)
- Generates drift report (YAML)

### 3. Data Transformation
- KNN Imputer for missing values
- Feature preprocessing
- Saves transformed NumPy arrays & preprocessing object

## ğŸ“ Project Structure
NetworkSecurity/
â”œâ”€â”€ networksecurity/
â”‚   â”œâ”€â”€ components/          # Pipeline components
â”‚   â”œâ”€â”€ constant/           # Configuration constants
â”‚   â”œâ”€â”€ entity/            # Data classes (configs, artifacts)
â”‚   â”œâ”€â”€ utils/             # Utility functions
â”‚   â”œâ”€â”€ exception/         # Custom exceptions
â”‚   â””â”€â”€ logging/           # Logging setup
â”œâ”€â”€ data_schema/           # Schema definitions
â”œâ”€â”€ Network_Data/          # Raw data
â”œâ”€â”€ Artifacts/             # Generated outputs
â”œâ”€â”€ main.py               # Entry point
â””â”€â”€ push_data.py          # Data upload utility


 ğŸ“Š Output Structure
 Artifacts/MM_DD_YYYY_HH_MM_SS/
â”œâ”€â”€ data_ingestion/
â”‚   â”œâ”€â”€ feature_store/phisingData.csv
â”‚   â””â”€â”€ ingested/{train,test}.csv
â”œâ”€â”€ data_validation/
â”‚   â”œâ”€â”€ validated/{train,test}.csv
â”‚   â””â”€â”€ drift_report/report.yaml
â””â”€â”€ data_transformation/
    â”œâ”€â”€ transformed_data/{train,test}.npy
    â””â”€â”€ transformed_object/preprocessing.pkl

ğŸ“ Configuration
Key settings in networksecurity/constant/training_pipeline/__init__.py:
TARGET_COLUMN: Target variable name
DATA_INGESTION_TRAIN_TEST_SPLIT_RATION: Split ratio (default: 0.2)
DATA_TRANSFORMATION_IMPUTER_PARAMS: KNN Imputer parameters


ğŸ¤ Contributing
Contributions welcome! Please open an issue or submit a PR.


ğŸ‘¤ Author
Priyanshu Ranjan
Email: priyanshujaiz341@gmail.com